{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>malicious</th>\n",
       "      <th>clean1</th>\n",
       "      <th>hanspell</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13734</th>\n",
       "      <td>이런 틀딱 드립은 지양해라.. 그런건 탑골공원에서나 먹힌다</td>\n",
       "      <td>1</td>\n",
       "      <td>이런 틀딱 드립은 지양해라 그런건 탑골공원에서나 먹힌다</td>\n",
       "      <td>이런 틀딱 드립은 지양해라 그런 건 탑골공원에서 나 먹힌다</td>\n",
       "      <td>hate-speech 드립은 지양해라 그런 건 탑골 공원에서나 먹힌다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>그래 잘한다 계속 칭찬해줘 잘하고있어</td>\n",
       "      <td>0</td>\n",
       "      <td>그래 잘한다 계속 칭찬해줘 잘하고있어</td>\n",
       "      <td>그래 잘한다 계속 칭찬해 줘 잘하고 있어</td>\n",
       "      <td>그래 잘한다 계속 칭찬해 줘 잘하고 있어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>난 절대로 브래드피트랑은 안논다 @.@</td>\n",
       "      <td>1</td>\n",
       "      <td>난 절대로 브래드피트랑은 안논다</td>\n",
       "      <td>난 절대로 브래드 피트랑은 안 논다</td>\n",
       "      <td>난 절대로 브래드 피트랑은 안 논다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25767</th>\n",
       "      <td>저표도 호남이 주작한거같은데?</td>\n",
       "      <td>1</td>\n",
       "      <td>저표도 호남이 주작한거같은데</td>\n",
       "      <td>지표도 호남이 주작한 거 같은데</td>\n",
       "      <td>저표도 호남이 주작한 거 같은데.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25412</th>\n",
       "      <td>뭔 레즈가 상처받노 또 또 레즈머리채 잡노 똥꼬충 후팔놈들이ㅡㅡ 지들 얘기에 아무 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>뭔 레즈가 상처받노 또 또 레즈머리채 잡노 똥꼬충 후팔놈들이 지들 얘기에 아무 상관...</td>\n",
       "      <td>뭔 레즈가 상처받노 또 또 레즈 머리채 잡노 똥꼬충 후발 놈들이 자기들 얘기에 아무...</td>\n",
       "      <td>왜 레즈가 상처받냐 또 또 레즈 머리채 잡니 똥꼬충 후팔놈들이 자기들 얘기에 아무 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>인맥자랑, 보여주기식 그이상 그이하도 아니다</td>\n",
       "      <td>1</td>\n",
       "      <td>인맥자랑 보여주기식 그이상 그이하도 아니다</td>\n",
       "      <td>인맥 자랑 보여주기식 그 이상 그 이하도 아니다</td>\n",
       "      <td>예전엔 인맥 자랑 보여 주기 그 이상 그 이하도 아니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  malicious  \\\n",
       "13734                   이런 틀딱 드립은 지양해라.. 그런건 탑골공원에서나 먹힌다          1   \n",
       "4496                                그래 잘한다 계속 칭찬해줘 잘하고있어          0   \n",
       "6669                               난 절대로 브래드피트랑은 안논다 @.@          1   \n",
       "25767                                   저표도 호남이 주작한거같은데?          1   \n",
       "25412  뭔 레즈가 상처받노 또 또 레즈머리채 잡노 똥꼬충 후팔놈들이ㅡㅡ 지들 얘기에 아무 ...          1   \n",
       "11289                           인맥자랑, 보여주기식 그이상 그이하도 아니다          1   \n",
       "\n",
       "                                                  clean1  \\\n",
       "13734                    이런 틀딱 드립은 지양해라 그런건 탑골공원에서나 먹힌다    \n",
       "4496                               그래 잘한다 계속 칭찬해줘 잘하고있어    \n",
       "6669                                  난 절대로 브래드피트랑은 안논다    \n",
       "25767                                   저표도 호남이 주작한거같은데    \n",
       "25412  뭔 레즈가 상처받노 또 또 레즈머리채 잡노 똥꼬충 후팔놈들이 지들 얘기에 아무 상관...   \n",
       "11289                           인맥자랑 보여주기식 그이상 그이하도 아니다    \n",
       "\n",
       "                                                hanspell  \\\n",
       "13734                  이런 틀딱 드립은 지양해라 그런 건 탑골공원에서 나 먹힌다    \n",
       "4496                             그래 잘한다 계속 칭찬해 줘 잘하고 있어    \n",
       "6669                                난 절대로 브래드 피트랑은 안 논다    \n",
       "25767                                 지표도 호남이 주작한 거 같은데    \n",
       "25412  뭔 레즈가 상처받노 또 또 레즈 머리채 잡노 똥꼬충 후발 놈들이 자기들 얘기에 아무...   \n",
       "11289                        인맥 자랑 보여주기식 그 이상 그 이하도 아니다    \n",
       "\n",
       "                                                      t5  \n",
       "13734            hate-speech 드립은 지양해라 그런 건 탑골 공원에서나 먹힌다.  \n",
       "4496                             그래 잘한다 계속 칭찬해 줘 잘하고 있어.  \n",
       "6669                                난 절대로 브래드 피트랑은 안 논다.  \n",
       "25767                                 저표도 호남이 주작한 거 같은데.  \n",
       "25412  왜 레즈가 상처받냐 또 또 레즈 머리채 잡니 똥꼬충 후팔놈들이 자기들 얘기에 아무 ...  \n",
       "11289                    예전엔 인맥 자랑 보여 주기 그 이상 그 이하도 아니다.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train = pd.read_csv('/home/kdt-admin/lsy/significant_clean1.csv')\n",
    "train = pd.read_csv('/home/kdt-admin/lsy/preprocess2.csv')\n",
    "# train=train[['clean1_result','malicious']]\n",
    "# train=train[['hanspell','malicious']]\n",
    "# train=train[['t5','malicious']]\n",
    "# test = pd.read_csv('/home/kdt-admin/lsy/significant_clean1_test.csv')\n",
    "# test = pd.read_csv('/home/kdt-admin/lsy/preprocess2_test.csv')\n",
    "# test=test[['clean1_result','malicious']]\n",
    "# test=test[['hanspell','malicious']]\n",
    "train.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# from ast import literal_eval\n",
    "\n",
    "# # 문자열을 리스트로 변환\n",
    "# def str_to_list(x):\n",
    "#     try:\n",
    "#         if type(x) == str:\n",
    "#         \treturn literal_eval(x)\n",
    "#         elif type(x) == list:\n",
    "#         \treturn x\n",
    "#     except: #해당 값이 null값이거나 오류가 있을 때, None을 return 하기\n",
    "#         return None\n",
    "# train['clean1_result']=train['clean1_result'].apply(str_to_list)\n",
    "# # test['clean1_result']=test['clean1_result'].apply(str_to_list)\n",
    "# train['clean1_result'] = train['clean1_result'].apply(lambda x: ' '.join(x))\n",
    "# # test['clean1_result'] = test['clean1_result'].apply(lambda x: ' '.join(x))\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['length'] = train['hanspell'].apply(lambda x: len(str(x)))\n",
    "train['length'] = train['t5'].apply(lambda x: len(str(x)))\n",
    "# test['length'] = test['clean1_result'].apply(lambda x: len(str(x)))\n",
    "# train['length'] = train['clean1'].apply(lambda x: len(str(x)))\n",
    "# test['length'] = test['clean1'].apply(lambda x: len(str(x)))\n",
    "train = train.loc[train['length'] > 5]\n",
    "# test = test.loc[test['length'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malicious\n",
       "1    17642\n",
       "0    10081\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['malicious'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2218249/1209799692.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train = train.groupby('malicious').apply(lambda x: x.sample(n=9500,random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "malicious\n",
       "0    9500\n",
       "1    9500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = train.groupby('malicious').apply(lambda x: x.sample(n=9500,random_state=42)).reset_index(drop=True)\n",
    "train['malicious'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = []\n",
    "\n",
    "# for text, label in zip(train['clean1'], train['malicious']):\n",
    "#   data = []\n",
    "#   data.append(text.strip())\n",
    "#   data.append(label)\n",
    "#   data_list.append(data)\n",
    "\n",
    "# test_data_list = []\n",
    "# for text, label in zip(test['clean1'], test['malicious']):\n",
    "#   data = []\n",
    "#   data.append(text.strip())\n",
    "#   data.append(label)\n",
    "#   test_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train, test_size = 0.2, shuffle=True, random_state = 12)\n",
    "# train, test = train_test_split(data_list, test_size = 0.2, shuffle=True, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments     저외모에 운동했으니그동안 여선배 여코치들한테 얼마나 보적보 갈굼당했을지상상도 안간다 ㄹㅇ\n",
       "malicious                                                    1\n",
       "clean1       저외모에 운동했으니그동안 여선배 여코치들한테 얼마나 보적보 갈굼당했을지상상도 안간다...\n",
       "hanspell     저 외모에 운동했으니 그동안 여자 선배여 코치들한테 얼마나 보적 보 갈굼 당했을지 ...\n",
       "t5           저 외모에 운동했으니 그동안 여 선배 여 코치들한테 얼마나 보적보 갈굼 당했을지 상...\n",
       "length                                                      57\n",
       "Name: 9764, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "\n",
    "labels = torch.tensor(list(train['malicious']), dtype=torch.long)\n",
    "dataset = CustomDataset(list(train['clean1']), labels, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  443,  7423,  1588,   266,  2566,  5652, 18412,   580,   469,  1085,\n",
      "           580,  1592,   399,  2819,  1267,   447,   449,   496,  1422, 20378,\n",
      "           371,  4861,   248,   400,  2485,  8537, 13258,   188,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3],\n",
      "        [ 2748,   340,  1323, 15142,  2544,   647,  4157,  1724, 20444,  2748,\n",
      "           468,  1300,  2005,   995,   188,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3],\n",
      "        [ 5108,  3126,   266,  6935,   393, 17452,   230,   476,  4055, 22994,\n",
      "          3754,  1821,   434,  1009, 10709,   525,  5344, 15916,   266,   811,\n",
      "          5896,  2766,   991, 22420,   188,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3],\n",
      "        [ 1403,  2145,  2190,   968,   369,  8696,   900, 12795,  1507,   570,\n",
      "           188,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3],\n",
      "        [ 1733,  1365, 10862,   188,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'label': tensor([1, 0, 1, 1, 0])}\n",
      "tensor([1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dataset, test_size=0.15, random_state=42)\n",
    "batch_size=16\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdt-admin/miniconda3/envs/kobert/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 1e-5\n",
    "epochs = 5\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Avg Loss: 0.4847\n",
      "Validation Loss: 0.3904 - Validation Accuracy: 0.8298\n",
      "precision: 1.0, recall: 0.6666666666666666, fscore: 0.8\n",
      "Epoch 2/5 - Avg Loss: 0.3411\n",
      "Validation Loss: 0.3702 - Validation Accuracy: 0.8338\n",
      "precision: 1.0, recall: 1.0, fscore: 1.0\n",
      "Epoch 3/5 - Avg Loss: 0.2636\n",
      "Validation Loss: 0.4127 - Validation Accuracy: 0.8386\n",
      "precision: 1.0, recall: 0.6, fscore: 0.75\n",
      "Epoch 4/5 - Avg Loss: 0.1872\n",
      "Validation Loss: 0.4695 - Validation Accuracy: 0.8307\n",
      "precision: 1.0, recall: 0.6666666666666666, fscore: 0.8\n",
      "Epoch 5/5 - Avg Loss: 0.1219\n",
      "Validation Loss: 0.5320 - Validation Accuracy: 0.8430\n",
      "precision: 1.0, recall: 0.8571428571428571, fscore: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "save_path = 'kcelectra_checkpoints/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 모델에 입력을 주어 예측을 생성합니다.\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # 모델 출력에서 로짓(분류에 대한 점수)을 얻습니다.\n",
    "        logits = outputs.logits\n",
    "        # 손실을 계산합니다.\n",
    "        loss = criterion(logits, labels)\n",
    "        # 역전파를 통해 그래디언트 계산\n",
    "        loss.backward()\n",
    "        # 옵티마이저를 사용해 가중치를 업데이트\n",
    "        optimizer.step()\n",
    "        # 에포크 전체 손실을 누적합니다.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # 에포크 평균 손실 계산\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    # 에포크별 손실 출력\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 모델 평가\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_dataloader:\n",
    "            # Validation 데이터 가져오기\n",
    "            val_input_ids = val_batch['input_ids']\n",
    "            val_attention_mask = val_batch['attention_mask']\n",
    "            val_labels = val_batch['label']\n",
    "\n",
    "            val_input_ids = val_input_ids.to(device)\n",
    "            val_attention_mask = val_attention_mask.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            # 모델 예측\n",
    "            val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n",
    "            val_logits = val_outputs.logits\n",
    "\n",
    "            # 손실 계산\n",
    "            val_loss = criterion(val_logits, val_labels)\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            val_preds = val_logits.argmax(dim=1)\n",
    "            correct += (val_preds == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    val_avg_loss = val_total_loss / len(valid_dataloader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(val_labels.cpu(), val_preds.cpu(), average='binary')\n",
    "    print(f'precision: {precision}, recall: {recall}, fscore: {fscore}')\n",
    "    torch.save(model.state_dict(), f'{save_path}model_epoch_{epoch+1}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
